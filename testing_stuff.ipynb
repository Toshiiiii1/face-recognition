{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\Python Code\\face_recognition\\FR_VM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=False, device=device, thresholds=[0.5, 0.5, 0.5])\n",
    "model = InceptionResnetV1(pretrained=\"vggface2\", classify=False).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_vectors = torch.load(\"./face_embeddings_vggface2.pt\") # a list of face embeddings\n",
    "face_names = np.load(\"./face_names_vggface2.npy\") # a list of names corresponding to the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches for the detected face:\n",
      "Name: Aaron_Peirsol, Similarity: 0.8256\n",
      "Name: German_Khan, Similarity: 0.6118\n",
      "Name: Greg_Owen, Similarity: 0.5431\n",
      "Name: Bob_Stoops, Similarity: 0.5336\n",
      "Name: Clint_Howard, Similarity: 0.5035\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return F.cosine_similarity(vec1, vec2, dim=0).item()\n",
    "\n",
    "image = Image.open(\"./dataset/test_image/Aaron_peirsol-2.jpg\").convert(\"RGB\")\n",
    "face_detected = mtcnn(image)\n",
    "\n",
    "similarities = []\n",
    "\n",
    "if face_detected is not None:\n",
    "    feature_vector = model(face_detected.unsqueeze(0).to(device))[0] # [1, 512]\n",
    "    for i, face_vector in enumerate(face_vectors):\n",
    "        sim = cosine_similarity(feature_vector, face_vector)\n",
    "        if sim > 0.5:\n",
    "            similarities.append((face_names[i], sim))\n",
    "    if similarities:\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        print(f\"Top matches for the detected face:\")\n",
    "        for name, sim in similarities[:5]:\n",
    "            print(f\"Name: {name}, Similarity: {sim:.4f}\")\n",
    "else:\n",
    "    print(\"No face detected in the image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the ways to extract feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(keep_all=False, device=device, thresholds=[0.6, 0.7, 0.9])\n",
    "model = InceptionResnetV1(pretrained=\"casia-webface\", classify=False).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./dataset/raw/lfw-deepfunneled/Aaron_Peirsol\\\\Aaron_Peirsol_0001.jpg', './dataset/raw/lfw-deepfunneled/Aaron_Peirsol\\\\Aaron_Peirsol_0002.jpg', './dataset/raw/lfw-deepfunneled/Aaron_Peirsol\\\\Aaron_Peirsol_0003.jpg', './dataset/raw/lfw-deepfunneled/Aaron_Peirsol\\\\Aaron_Peirsol_0004.jpg']\n"
     ]
    }
   ],
   "source": [
    "img_path = \"./dataset/raw/lfw-deepfunneled/Aaron_Peirsol\"\n",
    "# save_path = \"./dataset/cropped_images/cropped_Aaron_Guiel.jpg\"\n",
    "image_files = [os.path.join(img_path, f) for f in os.listdir(img_path)]\n",
    "print(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 160, 160])\n",
      "torch.Size([3, 160, 160])\n",
      "torch.Size([3, 160, 160])\n",
      "torch.Size([3, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "for img_file in image_files:\n",
    "    img = Image.open(img_file).convert(\"RGB\")\n",
    "    face = mtcnn(img)\n",
    "    print(face.shape)\n",
    "    if face is None:\n",
    "        continue\n",
    "    embedding = model(face.unsqueeze(0).to(device))\n",
    "    embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_tensor = torch.cat(embeddings, dim=0)\n",
    "mean_embedding = torch.mean(embeddings_tensor, dim=0)\n",
    "print(mean_embedding)\n",
    "mean_embedding_norm = torch.nn.functional.normalize(mean_embedding, p=2, dim=0)\n",
    "print(mean_embedding_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "test_img = \"./dataset/test_image/Aaron_peirsol-2.jpg\"\n",
    "img = Image.open(test_img)\n",
    "face = mtcnn(img, save_path=\"./dataset/cropped_images/cropped_Aaron_peirsol.jpg\")\n",
    "vector = model(face.unsqueeze(0).to(device))\n",
    "print(vector.shape)\n",
    "vector_norm = torch.nn.functional.normalize(vector, p=2, dim=1)\n",
    "print(vector_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between mean embedding and test image: 0.8256192207336426\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return F.cosine_similarity(vec1, vec2, dim=0).item()\n",
    "\n",
    "similarity = cosine_similarity(mean_embedding_norm, vector_norm[0])\n",
    "print(f\"Cosine similarity between mean embedding and test image: {similarity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FR_VM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
